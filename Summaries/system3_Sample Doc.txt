Human-quality text summarization systems are dicult to design, and even more dicult to evaluÃ¯Â¿Â¾ate, in part because documents can dier along several diÃ¯Â¿Â¾mensions, such as length, writing style and lexical usage.
Nevertheless, certain cues can often help suggest the selecÃ¯Â¿Â¾tion of sentences for inclusion in a summary.
This paper presents our analysis of news-article summaries generated by sentence selection.
Sentences are ranked for potential inclusion in the summary using a weighted combination of statistical and linguistic features.
To evaluate these features we use a normalized version of precision-recall curves, with a baseline of random sentence selection, as well as analyze the properties of such a baseline.
We illustrate our discussions with empirical reÃ¯Â¿Â¾sults showing the importance of corpus-dependent baseline summarization standards, compression ratios and carefully crafted long queries.
